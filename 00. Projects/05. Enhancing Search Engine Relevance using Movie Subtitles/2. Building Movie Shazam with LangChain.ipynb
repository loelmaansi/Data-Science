{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16c6718-6848-48ca-b355-b87fb818f629",
   "metadata": {},
   "source": [
    "# Enhancing Search Engine Relavance using video subtitles (Using Rags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde4cf6-c9c6-459a-bf8f-18437f9ea7f6",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "1. Load a Document\n",
    "2. Split it into Chunks\n",
    "3. Create vectors for each chunk and save them in a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3afbf7-558b-430d-a49c-4ee4b7d90f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c735562-d199-404b-9d74-eab345d34018",
   "metadata": {},
   "source": [
    "## 1. Load a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065febd6-72e6-48f3-9eea-9b7da9a2f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import random\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(2**30)  \n",
    "\n",
    "# Load the data\n",
    "loader = CSVLoader(file_path='data/subtitles.csv')\n",
    "documents = loader.load()\n",
    "\n",
    "# Sample 30% of the data\n",
    "documents = random.sample(documents, int(0.3 * len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b670558b-663d-45f0-be4e-2d5d550bd6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of loaded data: <class 'list'>\n",
      "Number of datapoints: 24749\n",
      "Type of each datapoints: <class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of loaded data:\", type(documents))\n",
    "\n",
    "print(\"Number of datapoints:\", len(documents))\n",
    "\n",
    "print(\"Type of each datapoints:\", type(documents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672c9feb-6a92-493a-9116-a43124ca614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65e8ff9-37e1-451f-a53c-a7c46d4ed344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(documents[0].page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b90c853-0921-4c5a-868e-5bb8c0493cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405eb5a5-d621-4fb0-9328-9bccf29cb9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata and assigning IDs: 100%|██████████| 24749/24749 [00:00<00:00, 70753.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract the relevant metadata from the page_content\n",
    "def extract_metadata(document, doc_id):\n",
    "    page_content = document.page_content\n",
    "\n",
    "    # Function to safely extract matches or return empty string if not found\n",
    "    def safe_extract(pattern, content):\n",
    "        match = re.search(pattern, content)\n",
    "        return match.group(1) if match else \"\"\n",
    "\n",
    "    # Extracting each field safely\n",
    "    name = safe_extract(r'name:\\s*(.*)', page_content)\n",
    "    season = safe_extract(r'season:\\s*(.*)', page_content)\n",
    "    year = safe_extract(r'year:\\s*(\\d{4})', page_content)\n",
    "    episode = safe_extract(r'episode:\\s*(.*)', page_content)\n",
    "\n",
    "    # Extract the subtitles (everything else) and clean it\n",
    "    subtitles = safe_extract(r'subtitles:\\s*(.*)', page_content)\n",
    "\n",
    "    # Creating new metadata dictionary\n",
    "    metadata = {\n",
    "        'name': name,\n",
    "        'season': season,\n",
    "        'year': year,\n",
    "        'episode': episode,\n",
    "    }\n",
    "\n",
    "\n",
    "    # Creating new document with ID, updated metadata, and page content\n",
    "    new_document = Document(\n",
    "        page_content=subtitles.strip(),  # Keeping only the subtitles text in page_content\n",
    "        metadata=metadata\n",
    "    )\n",
    "    \n",
    "    return new_document\n",
    "\n",
    "# Process all documents, extract metadata, and assign an id from 0 to len(documents)-1\n",
    "data = []\n",
    "for i, doc in enumerate(tqdm(documents, desc=\"Extracting metadata and assigning IDs\")):\n",
    "    new_doc = extract_metadata(doc, i)\n",
    "    data.append(new_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76754a5-9db8-476c-a239-c36970d82e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'northern exposure', 'season': '04', 'year': '1992', 'episode': '06'}\n",
      "script info title default file scripttype v . wrapstyle playresx playresy scaledborderandshadow yes audio file video file video aspect ratio video zoom video position v style format name fontname fontsize primarycolour secondarycolour outlinecolour backcolour bold italic underline strikeout scalex scaley spacing angle borderstyle outline shadow alignment marginl marginr marginv encoding style dialogue tahoma h fdfdfd h ff h f hc . . style dialogue tahoma h fdfdfd h ff h f hc . . style dialogue t\n"
     ]
    }
   ],
   "source": [
    "# Checking the result\n",
    "print(data[100].metadata)\n",
    "print(data[100].page_content[:500])  # Print first 100 chars of subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63547dcc-f15c-4452-9687-7671d3ddbcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a354941-9613-4dd9-ad38-a8e4895cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[0].page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40b0b3d-41d6-4125-b317-414445504027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef2cd17-8085-40f9-8c4f-365b8efbcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[0].ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36fdcfb-b648-402d-8e5e-b15e49a6f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta data in first document: \n",
      "{'name': 'sexify', 'season': '02', 'year': '2023', 'episode': '04'}\n",
      "\n",
      "Subtitles in First document: \n",
      "we had a meeting yesterday with the people who run sexiguy . you stupid bastard you stole our idea pathetic thief you haven t got any original thought you are disgusting you re disgusting awful and disgusting it wa a very productive talk that we were able to have with them and well we were able to explain our rationale to them . and we also took the chance to hear them out . what did i steal from you you be quiet we re at my place . i ll say what i want be quiet be quiet exhales the craziest thi\n"
     ]
    }
   ],
   "source": [
    "print('Meta data in first document: ')\n",
    "print(data[0].metadata)\n",
    "print()\n",
    "print('Subtitles in First document: ')\n",
    "print(data[0].page_content[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635d64b-8554-4967-a5de-58417ed87e3c",
   "metadata": {},
   "source": [
    "## 2. Split it into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73896c7d-fb5a-4460-8a43-c2ac7ec4d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data: 100%|██████████| 24749/24749 [01:14<00:00, 330.18data/s]"
     ]
    }
   ],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "# chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "\n",
    "chunks = []\n",
    "for doc in tqdm(data, desc=\" Splitting data\", unit=\"data\"):\n",
    "    chunks.extend(text_splitter.split_documents([doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04420b35-a1ce-4e86-abd2-09e1c6236deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 24749\n",
      "\n",
      "Total number of documents inside list: 2751797\n",
      "\n",
      "Type of variable: <class 'list'>\n",
      "\n",
      "Type of each object inside the list: <class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "Total number of documents inside list: 2751797\n",
      "\n",
      "Content of first chunk:\n",
      "page_content='we had a meeting yesterday with the people who run sexiguy . you stupid bastard you stole our idea pathetic thief you haven t got any original thought you are disgusting you re disgusting awful and disgusting it wa a very productive talk that we were able to have with them and well we were able to' metadata={'name': 'sexify', 'season': '02', 'year': '2023', 'episode': '04'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Documents:\", len(documents))\n",
    "print()\n",
    "print(\"Total number of documents inside list:\", len(chunks))\n",
    "print()\n",
    "print(\"Type of variable:\", type(chunks))\n",
    "print()\n",
    "print(\"Type of each object inside the list:\", type(chunks[0]))\n",
    "print()\n",
    "print(\"Total number of documents inside list:\", len(chunks))\n",
    "print()\n",
    "print(\"Content of first chunk:\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521842a5-e233-4b18-8ab8-86e037b47db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b03c6cc-26ec-48ac-b23b-4bc5e7ddc2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b6d6fa9-44ed-479a-b91e-3fd8cac5b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "856627d3-0c98-4e07-b195-da5c7db51797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34fd7b0c-72cc-4ffb-98e7-2ed2f7b94957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2751797"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce78ae8-a473-4642-a200-dbfa66274a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4e53d-101b-4f86-a75e-3ac39aaf8a1f",
   "metadata": {},
   "source": [
    "## 3. Create vectors for each chunk and save them in a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d9bb6e-336c-4844-8fd4-6fd0bd5c5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/openai_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e967902-5cfb-4913-b336-2ec334645449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/opentelemetry/proto/collector/trace/v1/trace_service_pb2_grpc.py:26: RuntimeWarning: The grpc package installed is at version 1.62.2, but the generated code in opentelemetry/proto/collector/trace/v1/trace_service_pb2_grpc.py depends on grpcio>=1.63.2. Please upgrade your grpc module to grpcio>=1.63.2 or downgrade your generated code using grpcio-tools<=1.62.2. This warning will become an error in 1.65.0, scheduled for release on June 25, 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# Define an embedding class to wrap SentenceTransformer\n",
    "class SentenceTransformerEmbedding(Embeddings):\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Generate embeddings for multiple documents.\"\"\"\n",
    "        return self.model.encode(texts, convert_to_tensor=False).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Generate an embedding for a single query.\"\"\"\n",
    "        return self.model.encode([text], convert_to_tensor=False)[0].tolist()\n",
    "\n",
    "# Create the embedding function\n",
    "embedding_function = SentenceTransformerEmbedding('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a09a130-db90-4b3f-afec-aab13ab30566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0993fa-6de6-406a-be98-dffb0b12d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB with the embedding function\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma(\n",
    "    collection_name=\"vector_database\",\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=\"./chroma_db_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d3e578b-fcbc-4fb3-8d2e-ec67cb5b27c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|██████████| 27518/27518 [6:00:30<00:00,  1.27it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents successfully added to the collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define batch size for processing\n",
    "batch_size = 100  # Adjust based on performance needs\n",
    "\n",
    "# Ensure chunks is a list of LangChain Document objects\n",
    "assert isinstance(chunks, list) and all(isinstance(chunk, Document) for chunk in chunks), \\\n",
    "    \"Chunks must be a list of LangChain Document objects\"\n",
    "\n",
    "# Adding documents\n",
    "for i in tqdm(range(0, len(chunks), batch_size), desc=\"Adding Documents\"):\n",
    "    batch = chunks[i:i + batch_size]\n",
    "    db.add_documents(batch)\n",
    "\n",
    "print(\"Documents successfully added to the collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9571a49-dd94-489c-a9c9-8f628e5cfe74",
   "metadata": {},
   "source": [
    "Building an End-to-End RAG Chain\n",
    "- Step 1: Initialize an embedding_model\n",
    "- Step 2: Initialize the Chroma DB Connection\n",
    "- Step 3: Create a Retriever Object\n",
    "- Step 4: Initialize a Chat Prompt Template\n",
    "- Step 5: Initialize a Generator (i.e. Chat Model)\n",
    "- Step 6: Initialize a Output Parser\n",
    "- Step 7: Define a RAG Chain\n",
    "- Step 8: Invoke the Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0732bf-95b2-463b-96b8-c9245c5d38c4",
   "metadata": {},
   "source": [
    "# **Retrievers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae05904-1629-4e6a-aa9c-f77f1c3a1048",
   "metadata": {},
   "source": [
    "## Step 1 - Initialize an embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76ca8c9-9169-4c7c-84a3-03db320013dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# Define an embedding class to wrap SentenceTransformer\n",
    "class SentenceTransformerEmbedding(Embeddings):\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Generate embeddings for multiple documents.\"\"\"\n",
    "        return self.model.encode(texts, convert_to_tensor=False).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Generate an embedding for a single query.\"\"\"\n",
    "        return self.model.encode([text], convert_to_tensor=False)[0].tolist()\n",
    "\n",
    "# Create the embedding function\n",
    "embedding_function = SentenceTransformerEmbedding('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a61c4e-31d8-4789-9ff1-faaa6fe2fbc8",
   "metadata": {},
   "source": [
    "## Step 2 - Initialize a ChromaDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72a1224-bcbd-4abd-b080-17bf716e2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "db = Chroma(collection_name = \"vector_database\", \n",
    "            embedding_function = embedding_function, \n",
    "            persist_directory = \"./chroma_db_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87e1f8f-cea5-4895-9a1a-47239c3d3c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x17e6bf410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c8d64-965f-434f-a8ad-5fb34d9ae0b4",
   "metadata": {},
   "source": [
    "## Step 3: Create a Retriever Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035b4902-5b0e-4845-b634-91746d926ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converting CHROMA db connection to Retriever Object\n",
    "retriever = db.as_retriever(search_type = \"similarity\",\n",
    "                            search_kwargs = {\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345081c7-6047-4301-8e8d-136ee4fcdc05",
   "metadata": {},
   "source": [
    "## Step 4: Initialize a Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd54a46-4ae7-49a7-9dec-5ef66ba6fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based solely on the following context:\n",
    "{context}\n",
    "\n",
    "Based on the given subtitle/dialogues below:\n",
    "{question}\n",
    "\n",
    "Provide only the title of the movie.\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a1ae9-c031-41fc-a0b3-58ea2b26f566",
   "metadata": {},
   "source": [
    "## Step 5: Initialize a Generator (i.e. Chat Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b7547d-85bc-406e-84d4-f751d1684913",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/openai_key.txt')\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8750b5f5-bc64-418f-8fce-8140e1bcace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenAI ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d8fed-6632-4172-aa18-46e58903dd53",
   "metadata": {},
   "source": [
    "## Step 6: Initialize a Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f013a928-9c71-44da-a779-e942752c09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefb773-289e-4e89-bb7c-b6230a537a59",
   "metadata": {},
   "source": [
    "## Step 7: Define a RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1fe7051-52af-464f-ba6f-0bfcef18e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt_template | chat_model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9047120-be34-4c02-8c61-0f585ba175d1",
   "metadata": {},
   "source": [
    "## Step 8: Invoke the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14ecdc53-d1d1-40e3-b03f-c4bfb15c4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Big man in a suit of armor, take that off what are you?, \n",
    "genius billionaire playboy philanthropist, \n",
    "I know guys with none of that worth 10 of you, I’ve seen the footage the only thing you really fight for is yourself, \n",
    "you’re not the guy to make the sacrifice play to lay down on a wire or let the other guy crawl over you! \n",
    "I think I would just cut the wire.  \n",
    "Always a way out, you know you may not be a threat but you stop pretending to be a hero! \n",
    "A hero like you, you’re a laboratory experiment rogers everything special about came out of a bottle\"\"\"\n",
    "\n",
    "# transcription = client.audio.transcriptions.create(\n",
    "#     model=\"whisper-1\", \n",
    "#     file=open('data/query.wav', \"rb\"))\n",
    "\n",
    "# query = transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9ac9f19-f1b1-49bf-86b7-c512dfacff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Endgame\n",
      "CPU times: user 26.4 ms, sys: 43.6 ms, total: 70 ms\n",
      "Wall time: 636 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b0e69-a7db-4882-9bd2-c874bfcf7840",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55fa4c52-c013-4831-98cd-813a24f0d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_data_long_dialogues = [\n",
    "    {\n",
    "        \"query\": \"\"\"Big man in a suit of armor, take that off what are you?,\n",
    "genius billionaire playboy philanthropist,\n",
    "I know guys with none of that worth 10 of you, I’ve seen the footage the only thing you really fight for is yourself,\n",
    "you’re not the guy to make the sacrifice play to lay down on a wire or let the other guy crawl over you!\n",
    "I think I would just cut the wire.\n",
    "Always a way out, you know you may not be a threat but you stop pretending to be a hero!\n",
    "A hero like you, you’re a laboratory experiment rogers everything special about came out of a bottle\"\"\",\n",
    "        \"expected_title\": \"The Avengers\" # Your example\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"\"\"Don't talk like one of them, you're not! Even if you'd like to be. To them, you're just a freak, like me! They need you right now, but when they don't, they'll cast you out, like a leper! See, their morals, their code... it's a bad joke. Dropped at the first sign of trouble. They're only as good as the world allows them to be. I'll show you. When the chips are down, these... these civilized people? They'll eat each other. See, I'm not a monster. I'm just ahead of the curve.\"\"\",\n",
    "        \"expected_title\": \"The Dark Knight\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"\"\"The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. That you are a slave, Neo. Like everyone else, you were born into bondage. Born into a prison that you cannot smell or taste or touch. A prison for your mind.\"\"\",\n",
    "        \"expected_title\": \"The Matrix\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"\"\"There's a passage I got memorized. Ezekiel 25:17. 'The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness, for he is truly his brother's keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy My brothers. And you will know My name is the Lord when I lay My vengeance upon thee.'\"\"\",\n",
    "        \"expected_title\": \"Pulp Fiction\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"\"\"You're not your job. You're not how much money you have in the bank. You're not the car you drive. You're not the contents of your wallet. You're not your f*cking khakis. We're the middle children of history, man. No purpose or place. We have no Great War. No Great Depression. Our Great War's a spiritual war... our Great Depression is our lives.\"\"\",\n",
    "        \"expected_title\": \"Fight Club\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"\"\"It's an energy field created by all living things. It surrounds us and penetrates us; it binds the galaxy together. A Jedi can feel the Force flowing through him. It controls your actions, but it also obeys your commands. You will learn to use it, just as your father did.\"\"\", # Adapted from Obi-Wan's explanation\n",
    "        \"expected_title\": \"Star Wars: Episode IV - A New Hope\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275fd464-cff3-4192-abc6-570ec7d6a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG chain: 100%|██████████| 6/6 [00:02<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "results = []\n",
    "\n",
    "for item in tqdm(ground_truth_data_long_dialogues, desc=\"Evaluating RAG chain\"):\n",
    "    query = item['query']\n",
    "    expected_title = item['expected_title']\n",
    "\n",
    "    try:\n",
    "        predicted_title = rag_chain.invoke(query)\n",
    "    except Exception as e:\n",
    "        predicted_title = f\"Error: {str(e)}\" # Handle potential errors during invocation\n",
    "\n",
    "    results.append({\n",
    "        'query': query,\n",
    "        'expected_title': expected_title,\n",
    "        'predicted_title': predicted_title\n",
    "    })\n",
    "\n",
    "# Convert results to a Pandas DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c0bffa1-3218-4979-8bc1-c5cb1d879371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>expected_title</th>\n",
       "      <th>predicted_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big man in a suit of armor, take that off what...</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>Iron Man 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't talk like one of them, you're not! Even ...</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>The Dark Knight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Matrix is everywhere. It is all around us....</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>The Matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There's a passage I got memorized. Ezekiel 25:...</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're not your job. You're not how much money...</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>Fight Club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query   expected_title  \\\n",
       "0  Big man in a suit of armor, take that off what...     The Avengers   \n",
       "1  Don't talk like one of them, you're not! Even ...  The Dark Knight   \n",
       "2  The Matrix is everywhere. It is all around us....       The Matrix   \n",
       "3  There's a passage I got memorized. Ezekiel 25:...     Pulp Fiction   \n",
       "4  You're not your job. You're not how much money...       Fight Club   \n",
       "\n",
       "   predicted_title  \n",
       "0       Iron Man 2  \n",
       "1  The Dark Knight  \n",
       "2       The Matrix  \n",
       "3     Pulp Fiction  \n",
       "4       Fight Club  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00eeeb11-12b6-46e9-8e36-c1331b72152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_expected_title</th>\n",
       "      <th>normalized_predicted_title</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the avengers</td>\n",
       "      <td>iron man 2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the dark knight</td>\n",
       "      <td>the dark knight</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the matrix</td>\n",
       "      <td>the matrix</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pulp fiction</td>\n",
       "      <td>pulp fiction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fight club</td>\n",
       "      <td>fight club</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  normalized_expected_title normalized_predicted_title  is_correct\n",
       "0              the avengers                 iron man 2       False\n",
       "1           the dark knight            the dark knight        True\n",
       "2                the matrix                 the matrix        True\n",
       "3              pulp fiction               pulp fiction        True\n",
       "4                fight club                 fight club        True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_title(title):\n",
    "    if not isinstance(title, str):\n",
    "        return \"\" \n",
    "    title = title.lower().strip()\n",
    "    return title\n",
    "\n",
    "results_df['normalized_expected_title'] = results_df['expected_title'].apply(normalize_title)\n",
    "results_df['normalized_predicted_title'] = results_df['predicted_title'].apply(normalize_title)\n",
    "\n",
    "results_df['is_correct'] = (results_df['normalized_predicted_title'] == results_df['normalized_expected_title'])\n",
    "\n",
    "results_df[['normalized_expected_title', 'normalized_predicted_title', 'is_correct']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53189bdf-69d6-4961-a84f-9b7ecf0ade0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Queries: 6\n",
      "Correct Predictions: 5\n",
      "Exact Match Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Exact Match Accuracy\n",
    "correct_predictions = results_df['is_correct'].sum()\n",
    "total_queries = len(results_df)\n",
    "accuracy = correct_predictions / total_queries\n",
    "\n",
    "print(f\"\\nTotal Queries: {total_queries}\")\n",
    "print(f\"Correct Predictions: {correct_predictions}\")\n",
    "print(f\"Exact Match Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aec7042d-c73a-486c-aada-1279f84be0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "accuracy = results_df['is_correct'].sum() / len(results_df)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a00d64-604b-41f4-9b6a-5d08c47f08c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
