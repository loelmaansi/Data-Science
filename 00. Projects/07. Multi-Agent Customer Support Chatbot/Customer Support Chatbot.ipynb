{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a245cc-b7b9-4bdc-ac18-42619dc43329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-core langchain-google-genai langgraph pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8602c252-ad6a-4c7d-8980-1965f0e74efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa08e659-787d-484b-827e-fa70b8f44555",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys/gemini.txt\")\n",
    "\n",
    "GOOGLE_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a80e39-286f-4dea-9974-2efcad76a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys/langsmith_api_key.txt\")\n",
    "\n",
    "LANGCHAIN_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd50237b-37be-44a7-8a80-389ef3a22198",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_TRACING_V2 = 'true'\n",
    "LANGCHAIN_PROJECT = 'CustomerSupportAgent-Langgraph'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3907c88-6aaf-41dc-9ff8-a6164d652db7",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ec28f-5c27-47ed-b57b-a99635664be4",
   "metadata": {},
   "source": [
    "### kb_data.txt content\n",
    "- Technical Issue: The 'Server Timeout' error (code 504) is usually caused by heavy network traffic. Try clearing your cache and cookies.\n",
    "- Technical Issue: For 'Login Failed' errors (code 401), reset your password using the 'Forgot Password' link. If that fails, contact human support.\n",
    "- General Info: Our business hours are Monday-Friday, 9 AM to 5 PM EST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35aac25-316a-4029-bc46-b830b1e3be44",
   "metadata": {},
   "source": [
    "## 01. Environment Setup and State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5a9de9-bb5e-4b01-87eb-ce11a0411fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "from typing import TypedDict, List, Annotated\n",
    "from operator import add\n",
    "\n",
    "# LangChain and LangGraph imports\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 0. ENVIRONMENT SETUP & STATE DEFINITION ---\n",
    "\n",
    "# 0.1 SECURE KEY LOADING & LLM INITIALIZATION\n",
    "# This section MUST set the keys as environment variables\n",
    "try:\n",
    "    with open(\"keys/gemini.txt\", \"r\") as f:\n",
    "        # ðŸŒŸ FIX: Set as OS Environment Variable\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = f.read().strip() \n",
    "    \n",
    "    with open(\"keys/langsmith_api_key.txt\", \"r\") as f:\n",
    "        # ðŸŒŸ FIX: Set as OS Environment Variable\n",
    "        os.environ[\"LANGCHAIN_API_KEY\"] = f.read().strip()\n",
    "\n",
    "    # ðŸŒŸ FIX: Set LangSmith vars as OS Environment Variables\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"CustomerSupportAgent-LangGraph\" \n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Required key file not found: {e.filename}. Please create the file.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# LLM Setup (This will now find the key in os.environ)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n",
    "\n",
    "# 0.2 Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add]\n",
    "    intent: str\n",
    "    issue_resolved: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98329a9d-2cc0-4275-83ee-15b428a88d93",
   "metadata": {},
   "source": [
    "## 02. Real-time data tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df25180-3adb-40a3-90c4-905f1eca0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_billing_status(user_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches real-time billing and subscription status by calling a local REST API.\n",
    "    API URL: http://1227.0.0.1:8000/api/billing\n",
    "    \"\"\"\n",
    "    API_ENDPOINT = \"http://127.0.0.1:8000/api/billing\"\n",
    "    print(f\"\\n--- TOOL: Calling Real-Time Billing API at {API_ENDPOINT} ---\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(f\"{API_ENDPOINT}?user_id={user_id}\")\n",
    "        if response.status_code == 200:\n",
    "            return f\"API Status: SUCCESS. Data: {json.dumps(response.json())}\"\n",
    "        elif response.status_code == 404:\n",
    "            return f\"API Status: User Not Found. Detail: {response.json().get('detail', 'N/A')}\"\n",
    "        else:\n",
    "            return f\"API Status: ERROR {response.status_code}.\"\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return \"API Connection Error: The local billing service (billing_api.py) is offline. Please run it.\"\n",
    "\n",
    "@tool\n",
    "def search_web_for_solution(query: str) -> str:\n",
    "    \"\"\"Performs a simulated real-time web search for technical articles.\"\"\"\n",
    "    print(f\"\\n--- TOOL: Performing Real-Time Web Search for: {query} ---\")\n",
    "    if \"timeout error\" in query.lower() or \"504\" in query.lower():\n",
    "        return \"Search Result: Official advisory on 'Server Timeout' (504): Issue is server-side congestion. Check status page.\"\n",
    "    elif \"login failed\" in query.lower() or \"401\" in query.lower():\n",
    "        return \"Search Result: Official notice 'Login Failed (401)': Use two-factor authentication for bypass.\"\n",
    "    else:\n",
    "        return f\"Search Result: Found 3 relevant articles for '{query}' from today's date.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96815e-68de-4638-a20b-23fb48da63d1",
   "metadata": {},
   "source": [
    "## 03. Agent Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbdd13-a4b0-4508-ab9e-65936c3fce1b",
   "metadata": {},
   "source": [
    "### 03.1. Node: Triage Agent (The Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91494e8-f6a6-4379-98db-5632e02a591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Node: Triage Agent (The Router) -- NOW FIXED\n",
    "def triage_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Classifies the intent of the latest message to determine the routing path.\"\"\"\n",
    "    print(\"\\n--- NODE: Triage Agent (Routing) ---\")\n",
    "    \n",
    "    # 1. ðŸŒŸ UPDATED & STRONGER PROMPT ðŸŒŸ\n",
    "    system_instruction = (\n",
    "    \"You are the Triage Agent. Your sole task is to classify the user's request. \"\n",
    "    \"Respond with ONLY one of the classification keywords.\"\n",
    "    \"\\n\\n\"\n",
    "    \"--- EXAMPLES ---\"\n",
    "    \"\\n\"\n",
    "    \"User Query: 'My invoice is wrong.' -> Response: billing\"\n",
    "    \"\\n\"\n",
    "    \"User Query: 'I can't log in.' -> Response: technical\"\n",
    "    \"\\n\"\n",
    "    \"User Query: 'What are your hours?' -> Response: general\"\n",
    "    \"\\n\"\n",
    "    \"User Query: 'Thanks so much!' -> Response: close\"\n",
    "    \"\\n\"\n",
    "    \"User Query: 'bye' -> Response: close\"\n",
    "    \"\\n\"\n",
    "    \"User Query: 'I need to integrate 500 systems...' -> Response: escalate\"\n",
    "    )    \n",
    "    # 2. Extract the User Message\n",
    "    user_message = state['messages'][-1]\n",
    "    \n",
    "    # 3. Pass BOTH System and Human Messages\n",
    "    messages_to_send = [\n",
    "        SystemMessage(content=system_instruction),\n",
    "        user_message\n",
    "    ]\n",
    "    \n",
    "    # 4. Invoke the LLM\n",
    "    response = llm.invoke(messages_to_send).content.strip().lower()\n",
    "    \n",
    "    # 5. Process and return the intent\n",
    "    # We also update the valid_intents set just in case\n",
    "    valid_intents = {'billing', 'technical', 'general', 'close', 'escalate'}\n",
    "    intent = response if response in valid_intents else 'escalate'\n",
    "    \n",
    "    print(f\"--- Intent Classified: {intent} ---\")\n",
    "    \n",
    "    # Initialize 'issue_resolved'\n",
    "    return {\"intent\": intent, \"issue_resolved\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56eb5c-cd50-4d84-bb61-0e1b0a1bb77a",
   "metadata": {},
   "source": [
    "### 03.2. Generic Specialized Agent Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb6f180-9450-436c-82e5-b33155167861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_specialized_agent(state: AgentState, tool_function, system_prompt: str) -> dict:\n",
    "    \n",
    "    # A simple way to log which agent is running\n",
    "    agent_name = tool_function.name  # <-- ðŸŒŸ THE FIX IS HERE\n",
    "    print(f\"\\n--- NODE: {agent_name} ---\")\n",
    "    \n",
    "    # 1. Bind the specific tool to the LLM\n",
    "    llm_with_tool = llm.bind_tools([tool_function])\n",
    "    \n",
    "    # 2. Set up the message history for this agent\n",
    "    history = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        state['messages'][-1] # Pass the latest user query\n",
    "    ]\n",
    "    \n",
    "    # 3. First LLM call (to decide on tool use)\n",
    "    response_ai = llm_with_tool.invoke(history)\n",
    "    \n",
    "    # 4. Check if the LLM decided to use a tool\n",
    "    if not response_ai.tool_calls:\n",
    "        # The LLM didn't use the tool, just responded.\n",
    "        print(\"--- AGENT FAILED: Did not call the required tool. ---\")\n",
    "        return {\"messages\": [response_ai], \"issue_resolved\": False}\n",
    "\n",
    "    # 5. Execute the tool call\n",
    "    print(f\"--- AGENT: Calling tool {response_ai.tool_calls[0]['name']}... ---\")\n",
    "    tool_call = response_ai.tool_calls[0]\n",
    "    \n",
    "    # Use .invoke() on the tool function directly\n",
    "    tool_output = tool_function.invoke(tool_call['args'])\n",
    "    \n",
    "    print(f\"--- TOOL: Output received. ---\")\n",
    "\n",
    "    # 6. Create the ToolMessage with the tool's output\n",
    "    tool_message = ToolMessage(content=str(tool_output), tool_call_id=tool_call['id'])\n",
    "    \n",
    "    # 7. Second LLM call (to generate a final answer based on tool output)\n",
    "    # Append the AI's tool call and the tool's result to the history\n",
    "    history.append(response_ai)\n",
    "    history.append(tool_message)\n",
    "    \n",
    "    # Call the LLM *without* tools this time to force a text response\n",
    "    final_response = llm.invoke(history) \n",
    "    \n",
    "    print(f\"--- AGENT SUCCESS: Generated final answer. ---\")\n",
    "\n",
    "    # 8. Set resolution status\n",
    "    # If the agent successfully completed the tool loop, we consider it resolved.\n",
    "    return {\n",
    "        \"messages\": [final_response], \n",
    "        \"issue_resolved\": True # <-- Set to True on success\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6bf9d9-cdf8-4760-a122-60858762b5c9",
   "metadata": {},
   "source": [
    "### 03.3. Specific Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576f2eb3-37bd-4898-b330-ff6ad05c04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_agent(state: AgentState) -> dict:\n",
    "    return run_specialized_agent(\n",
    "        state, \n",
    "        tool_function=search_web_for_solution, \n",
    "        system_prompt=\"You are a Technical Support Agent. You MUST use `search_web_for_solution` to find the most current solution. Provide the answer directly.\"\n",
    "    )\n",
    "\n",
    "def billing_agent(state: AgentState) -> dict:\n",
    "    return run_specialized_agent(\n",
    "        state, \n",
    "        tool_function=check_billing_status, \n",
    "        system_prompt=\"You are a Billing Specialist. You MUST use `check_billing_status` to fetch real-time account details. Provide a clear, actionable resolution.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a643941-3031-400f-8259-00a5eb807d4f",
   "metadata": {},
   "source": [
    "### 03.4. Node: Human Escalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed47f24-413b-444b-8eb4-31c0f326edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_handoff(state: AgentState) -> dict:\n",
    "    print(\"\\n--- NODE: Human Handoff ---\")\n",
    "    final_message = \"I apologize, but this request requires specialized knowledge. Your ticket has been **escalated to a human specialist** for immediate follow-up.\"\n",
    "    return {\"messages\": [AIMessage(content=final_message)], \"issue_resolved\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b071bfb2-ccca-4a4d-b7fe-f573cd54ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thank_you_and_end(state: AgentState) -> dict:\n",
    "    \"\"\"Node that provides a closing message and signals chat termination.\"\"\"\n",
    "    print(\"\\n--- NODE: Thank You & End ---\")\n",
    "    final_message = \"Thank you for using our automated support assistant! I'm glad I could help. Goodbye.\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_message)],\n",
    "        \"issue_resolved\": True # Sets the flag to True for the router\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1540293-333e-4907-9d6b-e486d6c3cc27",
   "metadata": {},
   "source": [
    "## 04. Conditional Routing Function & Graph Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c7960-b8cf-49dc-a528-ca8602c63709",
   "metadata": {},
   "source": [
    "### 04.1. Routing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c9c8ab5-5e73-467d-ae78-c54853c875e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_agent(state: AgentState) -> str:\n",
    "    if state['issue_resolved']:\n",
    "        return END\n",
    "    intent = state['intent']\n",
    "    if intent == 'billing':\n",
    "        return 'billing_agent'\n",
    "    elif intent == 'technical':\n",
    "        return 'technical_agent'\n",
    "    else: \n",
    "        return 'human_handoff'\n",
    "\n",
    "# ðŸŒŸ ADD THIS NEW FUNCTION ðŸŒŸ\n",
    "def route_after_specialist(state: AgentState) -> str:\n",
    "    \"\"\"A simpler router for after a specialist node has run.\"\"\"\n",
    "    if state['issue_resolved']:\n",
    "        return END\n",
    "    else:\n",
    "        return 'human_handoff'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe142d-e868-4d71-977c-780c76c299f4",
   "metadata": {},
   "source": [
    "### 04.2. Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e2974c-2474-4625-9408-63e13ac457ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"triage_agent\", triage_agent)\n",
    "workflow.add_node(\"technical_agent\", technical_agent)\n",
    "workflow.add_node(\"billing_agent\", billing_agent)\n",
    "workflow.add_node(\"human_handoff\", human_handoff)\n",
    "workflow.add_node(\"thank_you_and_end\", thank_you_and_end)\n",
    "workflow.set_entry_point(\"triage_agent\")\n",
    "\n",
    "# 1. Triage agent uses the main router\n",
    "workflow.add_conditional_edges(\n",
    "    \"triage_agent\", \n",
    "    route_agent,  # <-- This is correct\n",
    "    {'billing_agent': 'billing_agent', 'technical_agent': 'technical_agent', 'human_handoff': 'human_handoff', 'thank_you_and_end': 'thank_you_and_end', END: END}\n",
    ")\n",
    "\n",
    "# 2. ðŸŒŸ FIX: Specialist agents use the NEW, simpler router\n",
    "workflow.add_conditional_edges(\n",
    "    \"technical_agent\", \n",
    "    route_after_specialist,  # <-- Change this\n",
    "    {END: END, 'human_handoff': 'human_handoff'}\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"billing_agent\", \n",
    "    route_after_specialist,   # <-- Change this\n",
    "    {END: END, 'human_handoff': 'human_handoff'}\n",
    ")\n",
    "\n",
    "workflow.add_edge('human_handoff', END)\n",
    "workflow.add_edge('thank_you_and_end', END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccbba78-45f3-41e1-bf78-987cc2dd9ed6",
   "metadata": {},
   "source": [
    "## 05. Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91dc016b-b501-4c5d-ab37-e5c000c10e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** IMPORTANT: Ensure 'python billing_api.py' is running in a separate terminal. ***\n",
      "\n",
      "\n",
      "================================================================================\n",
      "| USER QUERY: I need help with my payment status, my ID is 12345. Is my invoice overdue?\n",
      "================================================================================\n",
      "\n",
      "--- NODE: Triage Agent (Routing) ---\n",
      "--- Intent Classified: billing ---\n",
      "\n",
      "--- NODE: check_billing_status ---\n",
      "--- AGENT: Calling tool check_billing_status... ---\n",
      "\n",
      "--- TOOL: Calling Real-Time Billing API at http://127.0.0.1:8000/api/billing ---\n",
      "--- TOOL: Output received. ---\n",
      "--- AGENT SUCCESS: Generated final answer. ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "| FINAL AGENT RESPONSE:\n",
      "| I apologize, but I'm unable to check your payment status or whether your invoice is overdue at this moment. The billing service is currently offline.\n",
      "\n",
      "Please try again later, or contact support if the issue persists.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "| USER QUERY: I am getting a 'Server Timeout' error. What is the latest fix?\n",
      "================================================================================\n",
      "\n",
      "--- NODE: Triage Agent (Routing) ---\n",
      "--- Intent Classified: technical ---\n",
      "\n",
      "--- NODE: search_web_for_solution ---\n",
      "--- AGENT: Calling tool search_web_for_solution... ---\n",
      "\n",
      "--- TOOL: Performing Real-Time Web Search for: Server Timeout error latest fix ---\n",
      "--- TOOL: Output received. ---\n",
      "--- AGENT SUCCESS: Generated final answer. ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "| FINAL AGENT RESPONSE:\n",
      "| The 'Server Timeout' error (often a 504 Gateway Timeout) indicates server-side congestion. There isn't a fix you can apply on your end. The latest advice is to check the status page of the service you are trying to access for updates on the issue.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "| USER QUERY: What is the long-term vision for your product roadmap?\n",
      "================================================================================\n",
      "\n",
      "--- NODE: Triage Agent (Routing) ---\n",
      "--- Intent Classified: escalate ---\n",
      "\n",
      "--- NODE: Human Handoff ---\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "| FINAL AGENT RESPONSE:\n",
      "| I apologize, but this request requires specialized knowledge. Your ticket has been **escalated to a human specialist** for immediate follow-up.\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_support_agent(query: str):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"| USER QUERY: {query}\")\n",
    "    print(\"=\"*80)\n",
    "    input_state = {\"messages\": [HumanMessage(content=query)]}\n",
    "    result = app.invoke(input_state)\n",
    "    final_message = result['messages'][-1].content\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"| FINAL AGENT RESPONSE:\")\n",
    "    print(f\"| {final_message}\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\\n*** IMPORTANT: Ensure 'python billing_api.py' is running in a separate terminal. ***\\n\")\n",
    "    run_support_agent(\"I need help with my payment status, my ID is 12345. Is my invoice overdue?\")\n",
    "    run_support_agent(\"I am getting a 'Server Timeout' error. What is the latest fix?\")\n",
    "    run_support_agent(\"What is the long-term vision for your product roadmap?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb18912-a94e-4e47-aba5-5653e1da9841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
